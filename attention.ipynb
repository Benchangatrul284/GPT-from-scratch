{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B: batch dimension  \n",
    "T: sequence length  \n",
    "D: feature dimension (hidden_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,D = 4,8,2\n",
    "x = torch.randn(B,T,D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We average the previous and current tokens.  \n",
    "![image](images/bow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,D))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1,:] #(T,D)\n",
    "        xbow[b,t,:] = torch.mean(xprev,dim=0) # reduce the time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use matrix multiplication to calculate the mean of the previous tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[8., 6.],\n",
      "        [5., 2.],\n",
      "        [4., 4.]])\n",
      "c=\n",
      "tensor([[8.0000, 6.0000],\n",
      "        [6.5000, 4.0000],\n",
      "        [5.6667, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3)) # lower traingular matrix\n",
    "a = a / torch.sum(a,dim=1,keepdim=True) # sum up the rows\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('b=')\n",
    "print(b)\n",
    "print('c=')\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix: \n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a stands for weight matrix\n",
    "# b stands for input matrix\n",
    "# c stands for output matrix\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei  = wei / torch.sum(wei,dim=1,keepdim=True) # sum up the rows\n",
    "print(f'weight matrix: \\n{wei}')\n",
    "xbow2 = wei @ x #(T,T) @ (B,T,D) -> (B,T,D)\n",
    "xbow2[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use softmax to produce the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix: \n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # mask out the upper triangle (masked-attention)\n",
    "wei = F.softmax(wei,dim=-1) # reduce the time dimension\n",
    "print(f'weight matrix: \\n{wei}')\n",
    "xbow3 = wei @ x\n",
    "xbow3[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous weight matrix simply averages the previous tokens and current tokens.  \n",
    "Can we modify the weight matrix to pay more attention to specific token?  \n",
    "Yes, we can use self-attention machanism to do so.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix: \n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8568, 0.1432, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.9035, 0.0319, 0.0646, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0794, 0.7826, 0.0262, 0.1117, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2599, 0.0619, 0.0666, 0.5537, 0.0579, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1648, 0.0910, 0.0811, 0.1171, 0.1276, 0.4185, 0.0000, 0.0000],\n",
      "         [0.5038, 0.0824, 0.0079, 0.2029, 0.0508, 0.0840, 0.0683, 0.0000],\n",
      "         [0.1233, 0.1467, 0.1079, 0.1274, 0.0938, 0.3208, 0.0458, 0.0343]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "B,T,D = 1,8,32\n",
    "x = torch.randn(B,T,D)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(D, head_size)\n",
    "query = nn.Linear(D, head_size)\n",
    "\n",
    "k = key(x) # (B,T,D) -> (B,T,head_size)\n",
    "q = query(x) # (B,T,D) -> (B,T,head_size)\n",
    "\n",
    "# previous, we simply set weight matrix to be all zeros\n",
    "wei = k @ q.transpose(2,1) # (B,T,head_size) @ (B,head_size,T) -> (B,T,T)\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # mask out the upper triangle (masked-attention)\n",
    "wei = F.softmax(wei,dim=-1)\n",
    "print(f'weight matrix: \\n{wei}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, We do dot product between attention weights and the embedding of the tokens. \n",
    "Here, we perform dot product between the attention weights and \"values\" of the tokens.  The value is produced by passing the embedding through a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = nn.Linear(D,head_size)\n",
    "v = value(x) # (B,T,D) -> (B,T,head_size)\n",
    "o = wei @ v # (B,T,T) @ (B,T,head_size) -> (B,T,head_size)\n",
    "o.shape # (B,T,head_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to recover the dimension of the output, we pass the dot product through a linear layer called output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input dimension is torch.Size([1, 8, 32]) and the output dimension is torch.Size([1, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "out = nn.Linear(head_size,D)\n",
    "o = out(o) # (B,T,head_size) -> (B,T,D)\n",
    "o.shape # (B,T,head_size)\n",
    "print(f'the input dimension is {x.shape} and the output dimension is {o.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled product attention\n",
    "since softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of k is 1.1766988039016724\n",
      "The variance of q is 0.8625323176383972\n",
      "The variance of wei is 16.994678497314453\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "print('The variance of k is', torch.var(k).item())\n",
    "print('The variance of q is', torch.var(q).item())\n",
    "wei = k @ q.transpose(2,1)\n",
    "print('The variance of wei is', torch.var(wei).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of wei is 1.0621674060821533\n"
     ]
    }
   ],
   "source": [
    "wei = k @ q.transpose(2,1) / (head_size**0.5)\n",
    "print('The variance of wei is', torch.var(wei).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
