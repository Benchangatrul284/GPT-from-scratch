{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B: batch dimension  \n",
    "T: sequence length  \n",
    "D: feature dimension (hidden_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "# B: batch dimension, T: sequence length, D: feature dimension (hidden size)\n",
    "B,T,D = 4,8,2\n",
    "x = torch.randn(B,T,D)\n",
    "xbow = torch.zeros((B,T,D))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1,:] #(T,D)\n",
    "        xbow[b,t,:] = torch.mean(xprev,dim=0) # reduce the time dimension\n",
    "\n",
    "x.shape == xbow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We average the previous and current tokens.  \n",
    "![image](images/bow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first batch of x is \n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n",
      "The first batch of xbow is \n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "print(f'The first batch of x is \\n{x[0]}')\n",
    "print(f'The first batch of xbow is \\n{xbow[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use matrix multiplication to calculate the mean of the previous tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[8., 6.],\n",
      "        [5., 2.],\n",
      "        [4., 4.]])\n",
      "c=\n",
      "tensor([[8.0000, 6.0000],\n",
      "        [6.5000, 4.0000],\n",
      "        [5.6667, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3)) # lower traingular matrix\n",
    "a = a / torch.sum(a,dim=1,keepdim=True) # sum up the rows\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print(f'a=\\n{a}')\n",
    "print(f'b=\\n{b}')\n",
    "print(f'c=\\n{c}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn matrix: \n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "The first batch of xbow2 is \n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "# a stands for attention matrix\n",
    "# b stands for input matrix\n",
    "# c stands for output matrix\n",
    "attn = torch.tril(torch.ones(T,T))\n",
    "attn = attn / torch.sum(attn,dim=1,keepdim=True) # sum up the rows\n",
    "print(f'attn matrix: \\n{attn}')\n",
    "xbow2 = attn @ x #(T,T) @ (B,T,D) -> (B,T,D)\n",
    "print(f'The first batch of xbow2 is \\n{xbow2[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use softmax to produce the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn matrix: \n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "The first batch of xbow3 is \n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "attn = torch.zeros(T,T)\n",
    "attn = attn.masked_fill(tril == 0, float('-inf')) # mask out the upper triangle (masked-attention)\n",
    "attn = F.softmax(attn,dim=-1) # reduce the time dimension\n",
    "xbow3 = attn @ x\n",
    "print(f'attn matrix: \\n{attn}')\n",
    "print(f'The first batch of xbow3 is \\n{xbow3[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous attention matrix simply averages the previous tokens and current tokens.  \n",
    "Can we modify the weight matrix to pay more attention to specific token?  \n",
    "Yes! We can use self-attention machanism to do so.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention matrix: \n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8568, 0.1432, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.9035, 0.0319, 0.0646, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0794, 0.7826, 0.0262, 0.1117, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2599, 0.0619, 0.0666, 0.5537, 0.0579, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1648, 0.0910, 0.0811, 0.1171, 0.1276, 0.4185, 0.0000, 0.0000],\n",
      "         [0.5038, 0.0824, 0.0079, 0.2029, 0.0508, 0.0840, 0.0683, 0.0000],\n",
      "         [0.1233, 0.1467, 0.1079, 0.1274, 0.0938, 0.3208, 0.0458, 0.0343]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "B,T,D = 1,8,32\n",
    "x = torch.randn(B,T,D)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(D, head_size)\n",
    "query = nn.Linear(D, head_size)\n",
    "\n",
    "k = key(x) # (B,T,D) -> (B,T,head_size)\n",
    "q = query(x) # (B,T,D) -> (B,T,head_size)\n",
    "\n",
    "# previous, we simply set weight matrix to be all zeros\n",
    "attn = k @ q.transpose(2,1) # (B,T,head_size) @ (B,head_size,T) -> (B,T,T)\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf')) # mask out the upper triangle (masked-attention)\n",
    "attn = F.softmax(attn,dim=-1)\n",
    "print(f'attention matrix: \\n{attn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we do dot product between attention weights and the embedding of the tokens. \n",
    "Here, we perform dot product between the attention weights and \"values\" of the tokens.  The value is produced by passing the embedding through a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = nn.Linear(D,head_size)\n",
    "v = value(x) # (B,T,D) -> (B,T,head_size)\n",
    "o = attn @ v # (B,T,T) @ (B,T,head_size) -> (B,T,head_size)\n",
    "o.shape # (B,T,head_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the dot product through a linear layer called output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input dimension is torch.Size([1, 8, 32]) and the output dimension is torch.Size([1, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "out = nn.Linear(head_size,D)\n",
    "o = out(o) # (B,T,head_size) -> (B,T,D)\n",
    "o.shape # (B,T,head_size)\n",
    "print(f'the input dimension is {x.shape} and the output dimension is {o.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled product attention\n",
    "We expect the variance to be close to 1, but after dot product, the variance will be close to head_size. We therefore divide the dot product by sqrt(head_size) to scale the variance back to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of k is 1.1766988039016724\n",
      "The variance of q is 0.8625323176383972\n",
      "The variance of attn is 16.994678497314453\n"
     ]
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "print('The variance of k is', torch.var(k).item())\n",
    "print('The variance of q is', torch.var(q).item())\n",
    "attn = k @ q.transpose(2,1)\n",
    "print('The variance of attn is', torch.var(attn).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of attn is 1.0621674060821533\n"
     ]
    }
   ],
   "source": [
    "attn = k @ q.transpose(2,1) / (head_size**0.5)\n",
    "print('The variance of attn is', torch.var(attn).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input dimension is torch.Size([1, 8, 32]) and the output dimension is torch.Size([1, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "class SHATTN(nn.Module):\n",
    "    '''\n",
    "    A simple single head of the self-attention mechanism.\n",
    "    '''\n",
    "    def __init__(self, hidden_size, head_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.head_size = head_size\n",
    "        self.query = nn.Linear(hidden_size, head_size)\n",
    "        self.key = nn.Linear(hidden_size, head_size)\n",
    "        self.value = nn.Linear(hidden_size, head_size)\n",
    "        self.out = nn.Linear(head_size, hidden_size)\n",
    "    def forward(self, x):\n",
    "        B,T,D = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        # compute attention matrix\n",
    "        attn = (q @ k.transpose(2, 1)) / (self.head_size ** 0.5)\n",
    "        attn = attn.masked_fill(torch.ones(T,T,device=x.device,dtype=torch.bool) == 0, float('-inf'))\n",
    "        attn = torch.softmax(attn, dim=-1) \n",
    "        o = attn @ v\n",
    "        out = self.out(o)\n",
    "        return out\n",
    "    \n",
    "x = torch.randn(B,T,D)\n",
    "attn = SHATTN(D,head_size)\n",
    "o = attn(x)\n",
    "print(f'the input dimension is {x.shape} and the output dimension is {o.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input dimension is torch.Size([1, 8, 32]) and the output dimension is torch.Size([1, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "class MHATTN(nn.Module):\n",
    "    '''\n",
    "    Implementation of multi-head attention mechanism.\n",
    "    '''\n",
    "    def __init__(self, hidden_size,num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = hidden_size // num_heads\n",
    "        self.heads = nn.ModuleList([SHATTN(self.head_size, self.head_size) for _ in range(num_heads)])\n",
    "        self.out = nn.Linear(hidden_size, hidden_size)\n",
    "    def forward(self, x):\n",
    "        # slice the hidden_size dimension into num_heads\n",
    "        B,T,D = x.shape\n",
    "        x = x.view(B,T,-1,self.head_size).transpose(1, 2)\n",
    "        # concatenate the heads along the hidden_size dimension\n",
    "        o = torch.cat([self.heads[i](x[:,i,:,:]) for i in range(self.num_heads)], dim=-1)\n",
    "        out = self.out(o)\n",
    "        return out\n",
    " \n",
    "x = torch.randn(B,T,D)\n",
    "attn = MHATTN(D,num_heads=4)\n",
    "o = attn(x)\n",
    "print(f'the input dimension is {x.shape} and the output dimension is {o.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
